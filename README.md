# Forum
Конечно! Вот аккуратная версия `README.md` для твоего проекта:  

---

# Telegram Бот + Локальная LLM через Ollama

## Описание
Этот проект включает:
- Телеграм-бота на Python (`bot.py`), который отвечает на сообщения.
- Скрипт для общения с локальной моделью через Ollama API (`ask_model.py`).

## Требования

- Python 3.10+
- Telegram Bot API токен
- Установленный Ollama
- Модель для Ollama (`qwen2.5-coder:3b` или любая другая)

---

## Установка

1. Клонируйте репозиторий:

```bash
git clone https://github.com/Dima51Al/Forum
cd Forum
```

2. Установите зависимости:

```bash
pip install -r requirements.txt

```

3. Создайте файл `.env` и добавьте туда ваш Telegram API токен:

```
API_TOKEN=ваш_токен_сюда
```

---

## Как запустить Ollama

1. Скачайте и установите [Ollama](https://ollama.com/).

2. Запустите сервер Ollama:

```bash
ollama serve
```

3. Загрузите нужную модель:

```bash
ollama pull qwen2.5-coder:3b
```

Проверьте, что Ollama работает на `http://127.0.0.1:11434`.

---

## Как запустить бота

1. Убедитесь, что в `.env` прописан ваш Telegram API токен.

2. Запустите бота:

```bash
python bot.py
```

Теперь бот будет отвечать в Телеграме.

---

## Дополнительный скрипт: Запросы к модели

Чтобы напрямую отправлять запросы локальной модели:

```bash
python ask_model.py
```

Введите любой текст, чтобы получить ответ от модели.  
Чтобы выйти, введите `выход`, `exit` или `quit`.

---
